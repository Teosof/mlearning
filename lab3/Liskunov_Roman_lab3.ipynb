{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Решающие деревья для задач классификации и регрессии\n",
    "Группа: ИВТ-М20.<br/>\n",
    "Студент: Лискунов Роман Геннадьвич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Union, Any\n",
    "from numpy import arange\n",
    "from pandas import (\n",
    "    DataFrame,\n",
    "    read_csv\n",
    ")\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    r2_score,\n",
    "    mean_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import (\n",
    "    DecisionTreeClassifier,\n",
    "    DecisionTreeRegressor\n",
    ")\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Прочтите данные из файлов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "transformators: DataFrame = DataFrame(\n",
    "    read_csv(\n",
    "        'data/transformators.csv',\n",
    "        sep=',',\n",
    "        header=0\n",
    "    )\n",
    ")\n",
    "regression: DataFrame = DataFrame(\n",
    "    read_csv(\n",
    "        'data/transformators_regression.csv',\n",
    "        sep=',',\n",
    "        header=0\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Отобразите несколько первых и несколько последних записей."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         H2        CO      C2H4      C2H2  label\n",
      "0  0.002590  0.016491  0.002876  0.000336      1\n",
      "1  0.002825  0.014728  0.001992  0.000339      1\n",
      "2  0.002764  0.017030  0.003394  0.000195      1\n",
      "3  0.000508  0.016334  0.004104  0.000380      1\n",
      "4  0.002654  0.021278  0.004068  0.000124      1\n",
      "            H2        CO      C2H4      C2H2  label\n",
      "2095  0.002549  0.009460  0.007465  0.000242      1\n",
      "2096  0.000915  0.005770  0.007230  0.000081      3\n",
      "2097  0.001565  0.002492  0.008529  0.000176      3\n",
      "2098  0.001688  0.020291  0.007305  0.000252      1\n",
      "2099  0.002935  0.028001  0.008048  0.000219      1\n",
      "         H2        CO      C2H4      C2H2  label\n",
      "0  0.002590  0.016491  0.002876  0.000336    541\n",
      "1  0.002825  0.014728  0.001992  0.000339    520\n",
      "2  0.002764  0.017030  0.003394  0.000195    583\n",
      "3  0.000508  0.016334  0.004104  0.000380    487\n",
      "4  0.002654  0.021278  0.004068  0.000124   1093\n",
      "            H2        CO      C2H4      C2H2  label\n",
      "2095  0.002549  0.009460  0.007465  0.000242   1093\n",
      "2096  0.000915  0.005770  0.007230  0.000081   1093\n",
      "2097  0.001565  0.002492  0.008529  0.000176    719\n",
      "2098  0.001688  0.020291  0.007305  0.000252    698\n",
      "2099  0.002935  0.028001  0.008048  0.000219    644\n"
     ]
    }
   ],
   "source": [
    "print(transformators.head())\n",
    "print(transformators.tail())\n",
    "print(regression.head())\n",
    "print(regression.tail())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Разбейте данные для классификации"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "transformators_train, transformators_test = train_test_split(transformators, test_size=0.3, train_size=0.7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Примените алгоритм дерева решений"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(max_depth=2)"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf: DecisionTreeClassifier = DecisionTreeClassifier(max_depth = 2)\n",
    "clf.fit(transformators_train, transformators_train.label)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Сделайте предсказание на тестовой выборке."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1 3 1 1 1 4 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 3 1 1 1 1 3 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 4 3 1 1 1 3 1 1 1 1 1 1 4 1 1 1 1 1 4 1 1 1 1 1 1 1 1 3 4\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 4 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 3 1 1 1 1 1 1 4 4 1 1 1 3 3 1 4\n",
      " 1 1 4 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 1 4 4 1 1 1 1 4 1 1 1 1\n",
      " 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 3 1 1 3 1 1\n",
      " 1 3 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 3 1 1 1 1 3 4 1 4 1 1 1 3 3 1 1 1\n",
      " 1 3 3 1 1 1 4 1 1 1 1 3 3 1 1 1 1 1 1 1 3 1 1 1 1 3 4 1 1 3 1 1 3 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 4 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1\n",
      " 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 4 3 4 1 4 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3\n",
      " 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 3 1 1 3 3 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 3 1 3 1 1 1 4 1 4 4 1 1 4 1 1 1 4 1 1 3 4 1 1 1 1 1 1 1 1 1 1 1\n",
      " 4 1 1 1 4 1 1 1 1 1 1 1 1 4 1 1 1 4 1 1 1 1 1 1 1 4 1 1 3 1 1 1 1 1 1 3 1\n",
      " 1 4 1 1 1 4 1 4 1 1 1 4 1 1 1 1 1 1 1 1 1 4 1 1 1 1 3 1 3 1 3 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 3 4 1 3 1 1 4 1 1 1 4 1\n",
      " 4 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 4 1 1 1 4 1 1 1\n",
      " 1 1 1 3 4 4 4 1 1 4 1 1 1 4 1 1 1 1 1 1 3 1 1 1 1 1 1 1 4 1 4 1 1 1 1 1 1\n",
      " 1]\n",
      "Test score: [0.95918367 0.95918367 0.95918367 0.95238095 0.95238095 0.95238095\n",
      " 0.95238095 0.95238095 0.95238095 0.95918367]\n"
     ]
    }
   ],
   "source": [
    "test: object = transformators_test.label\n",
    "pred: object = clf.predict(transformators_test)\n",
    "print(f\"Prediction: {pred}\")\n",
    "scores: object = cross_val_score(\n",
    "    clf,\n",
    "    transformators_train,\n",
    "    transformators_train.label,\n",
    "    cv=10,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "print(f\"Test score: {scores}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Выполните подбор гиперпараметров модели"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'max_depth': [0, 10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
      "                                       100, 110, 120, 130, 140],\n",
      "                         'min_samples_leaf': [0, 3, 6, 9, 12],\n",
      "                         'min_samples_split': [0, 2, 4, 6, 8]})\n"
     ]
    }
   ],
   "source": [
    "parameters: dict[str, Union[list[str], list[int]]] = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[x for x in range(0,150,10)],\n",
    "    'min_samples_split': [x for x in range(0,10,2)],\n",
    "    'min_samples_leaf': [x for x in range(0,15,3)]\n",
    "}\n",
    "grid: GridSearchCV = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    parameters,\n",
    "    cv=5\n",
    ")\n",
    "gs_result: Union[GridSearchCV, Any] = grid.fit(transformators_train, transformators_train.label)\n",
    "print(gs_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Заново обучите модель с подобранными гиперпараметрами"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "1.0\n",
      "[1 2 1 1 1 4 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 4 3 1 1 1 3 1 1 1 1 1 1 4 1 1 1 1 1 4 1 1 1 1 1 1 1 1 3 4\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 4 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 2 1 1 1 1 1 1 4 4 1 1 1 3 3 1 4\n",
      " 1 1 4 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 1 4 4 1 1 1 1 4 1 1 1 1\n",
      " 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 3 1 1 2 1 1\n",
      " 1 3 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 2 1 1 1 1 2 4 1 4 1 1 1 3 2 1 1 1\n",
      " 1 3 2 1 1 1 4 1 1 1 1 3 2 1 1 1 1 1 1 1 3 1 1 1 1 3 4 1 1 3 1 1 3 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 2 4 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1\n",
      " 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 4 2 4 1 4 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 3 1 1 3 2 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 1 2 1 1 1 4 1 4 4 1 1 4 1 1 1 4 1 1 2 4 1 1 1 1 1 1 1 1 1 1 1\n",
      " 4 1 1 1 4 1 1 1 1 1 1 1 1 4 1 1 1 4 1 1 1 1 1 1 1 4 1 1 2 1 1 1 1 1 1 3 1\n",
      " 1 4 1 1 1 4 1 4 1 1 1 4 1 1 1 1 1 1 1 1 1 4 1 1 1 1 3 1 2 1 3 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 3 4 1 3 1 1 4 1 1 1 4 1\n",
      " 4 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 4 1 1 1 4 1 1 1\n",
      " 1 1 1 2 4 4 4 1 1 4 1 1 1 4 1 1 1 1 1 1 3 1 1 1 1 1 1 1 4 1 4 1 1 1 1 1 1\n",
      " 1]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(gs_result.best_params_)\n",
    "print(gs_result.best_score_)\n",
    "print(gs_result.predict(transformators_test))\n",
    "pred: object = gs_result.predict(transformators_test)\n",
    "print(accuracy_score(test, pred, normalize=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Постройте итоговое дерево классификации"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "graph = export_graphviz(\n",
    "    clf,\n",
    "    out_file =  \"data/transformators.dot\",\n",
    "    filled = True,\n",
    "    rounded = True\n",
    ")\n",
    "print(graph)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Разбейте данные для регрессии"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "regression_train, regression_test = train_test_split(regression, test_size=0.3, train_size=0.7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10. Примените алгоритм дерева регрессии\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor()"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf: DecisionTreeRegressor = DecisionTreeRegressor()\n",
    "clf.fit(regression_train, regression_train.label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11. Сделайте предсказание на тестовой выборке"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [ 573. 1093.  618.  582.  764.  789. 1093.  780.  603.  752.  528. 1093.\n",
      "  555.  584. 1093.  687. 1093.  478.  755.  543.  781. 1093.  572.  543.\n",
      " 1093.  878.  583. 1093.  757. 1093.  473.  551.  659.  529.  466.  636.\n",
      " 1093.  537.  512.  785.  773.  764.  442.  827.  684.  881. 1093.  571.\n",
      " 1093. 1093.  837.  481. 1093. 1093.  524.  438.  673.  657. 1093. 1093.\n",
      "  814. 1093. 1093.  628. 1093. 1093.  421. 1093.  581.  752. 1093.  811.\n",
      " 1093. 1083.  737.  563.  569. 1093.  494.  546.  560.  551.  795.  546.\n",
      "  900.  711. 1093.  557.  540.  612.  762.  581.  956. 1093. 1093.  799.\n",
      " 1093.  696.  752. 1093.  494.  593.  910. 1093. 1093. 1093.  738.  609.\n",
      " 1093. 1093.  625.  654. 1093. 1093.  645.  603.  642.  551.  577.  865.\n",
      "  614.  546.  534. 1093. 1093.  534. 1051.  513.  540. 1093.  632.  510.\n",
      " 1093. 1093.  646.  667.  567.  430.  548.  584.  956.  820.  762.  468.\n",
      "  781.  529.  878.  504. 1093.  510. 1093. 1093. 1093.  870.  499.  674.\n",
      " 1093. 1093.  453.  740. 1093. 1093. 1093.  507.  704.  668.  583. 1093.\n",
      "  485. 1093. 1093. 1093.  477.  591. 1093.  537.  707.  671. 1093.  495.\n",
      "  738. 1093.  827.  656. 1093. 1093.  597.  933.  773. 1093.  464.  525.\n",
      "  514.  611.  477. 1085.  544.  851.  547.  780. 1093. 1093.  865.  542.\n",
      "  606.  647. 1093. 1093.  569.  822.  697.  910. 1093.  502. 1093. 1093.\n",
      " 1093.  828. 1093.  636.  525.  444.  833.  555. 1093.  647.  589.  862.\n",
      "  666.  692.  611.  506. 1093.  738.  570.  519.  459.  742. 1093.  444.\n",
      " 1093.  774. 1093. 1093.  550. 1093.  531. 1093.  671. 1093.  726.  786.\n",
      "  584.  481. 1093.  787. 1093. 1093.  800. 1093. 1093.  660.  875.  529.\n",
      "  609. 1093. 1093. 1093.  456. 1093.  598.  719.  537.  774.  542. 1093.\n",
      "  774.  668. 1093.  501. 1093.  542.  509. 1093.  654. 1051. 1093. 1093.\n",
      " 1093. 1093.  502.  593.  761.  511. 1093.  516. 1093.  484.  833.  543.\n",
      " 1093. 1093.  493.  512.  624.  717.  866. 1093.  633. 1093. 1065.  503.\n",
      " 1093.  483.  614.  765. 1093. 1093.  504. 1093. 1093.  490.  503.  590.\n",
      "  531.  522.  714.  980.  516.  658.  674. 1093. 1093. 1093. 1093.  652.\n",
      "  537.  665.  594. 1093. 1093.  576. 1093.  852.  670.  564. 1093.  594.\n",
      "  483.  832.  421.  507. 1093. 1093.  653.  623.  494.  557. 1093.  597.\n",
      "  774.  815.  956.  748. 1093.  721.  525.  575.  599. 1093.  482. 1093.\n",
      "  645.  524. 1093.  498.  865.  759.  580.  518. 1093. 1093.  550.  729.\n",
      " 1093. 1093.  572.  795.  583.  644.  667.  810.  537.  654.  644.  526.\n",
      "  508.  642.  578.  756. 1093.  534. 1093. 1093. 1093.  660.  845.  430.\n",
      "  652.  504.  544. 1093. 1093.  705. 1093.  388.  851.  560.  618.  663.\n",
      " 1093.  523. 1093.  575. 1093.  752.  801.  663. 1093. 1082.  504.  547.\n",
      "  526.  451. 1093.  618.  810.  790. 1093.  813.  843.  620.  453. 1093.\n",
      "  606.  802.  558. 1093.  794.  581.  764.  632.  787.  670. 1093. 1093.\n",
      " 1093. 1093. 1093.  527.  854.  774. 1093.  843.  767.  488. 1093.  511.\n",
      "  490.  509. 1093. 1093.  458.  694.  516. 1093. 1093. 1093. 1093.  711.\n",
      "  785.  851.  517.  859. 1093. 1093. 1093. 1093. 1093.  539.  483.  483.\n",
      "  851.  504.  659. 1093. 1051.  612.  550.  728. 1093.  507. 1093.  543.\n",
      "  536.  732.  746.  636. 1093. 1093.  759. 1093.  482.  560.  611.  572.\n",
      " 1093.  502. 1093.  646. 1093.  548. 1093.  738. 1093.  499.  458.  639.\n",
      "  410.  870.  449.  497.  495. 1093.  673.  750.  756.  550.  482.  720.\n",
      "  526. 1093.  687.  572. 1093.  581.  887. 1093. 1093.  510.  670. 1093.\n",
      "  880. 1093.  833. 1093.  495.  497.  468. 1093.  882. 1093.  714.  592.\n",
      " 1093.  840.  874.  496. 1093.  862.  856.  608.  752.  848.  825.  601.\n",
      " 1093.  862.  520.  758. 1093.  721.  709.  808.  828.  408.  710.  652.\n",
      "  817. 1093.  740.  840.  609.  668.  544.  467. 1093. 1093.  684. 1093.\n",
      " 1093.  592.  716. 1093.  537.  608.  752.  467.  448.  764.  434. 1093.\n",
      " 1093. 1093.  762.  881.  629.  501. 1093. 1093. 1093.  862.  636.  535.\n",
      "  837. 1093. 1093.  525.  518. 1093.]\n",
      "r2_score: 1.0\n",
      "mean_absolute_error: 0.492\n"
     ]
    }
   ],
   "source": [
    "test: object = regression_test.label\n",
    "pred: object = clf.predict(regression_test)\n",
    "print(f\"Prediction: {pred}\")\n",
    "print(f\"r2_score: {round(r2_score(test, pred), 3)}\")\n",
    "print(f\"mean_absolute_error: {round(mean_absolute_error(test, pred), 3)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 12. Выполните подбор гиперпараметров модели"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
      "             param_grid={'max_depth': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
      "                         'min_samples_leaf': array([1, 2, 3, 4]),\n",
      "                         'min_samples_split': array([2, 3, 4, 5, 6, 7, 8, 9]),\n",
      "                         'splitter': ('best', 'random')})\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'splitter':('best','random'),\n",
    "    'max_depth': arange(1,10),\n",
    "    'min_samples_split': arange(2,10),\n",
    "    'min_samples_leaf': arange(1,5)\n",
    "}\n",
    "grid: GridSearchCV = GridSearchCV(\n",
    "    DecisionTreeRegressor(),\n",
    "    parameters,\n",
    "    cv=5\n",
    ")\n",
    "gs_result: Union[GridSearchCV, Any] = grid.fit(regression_train, regression_train.label)\n",
    "print(gs_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 13. Заново обучите модель с подобранными гиперпараметрам"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "0.9999027454025988\n",
      "[ 572.33333333 1093.          618.33333333  582.          764.\n",
      "  789.66666667 1093.          780.          602.6         751.5\n",
      "  527.7        1093.          555.5         584.         1093.\n",
      "  686.         1093.          477.375       755.          543.\n",
      "  781.         1093.          572.33333333  543.         1093.\n",
      "  878.          583.         1093.          756.5        1093.\n",
      "  471.66666667  551.66666667  658.5         529.8         466.5\n",
      "  636.         1093.          537.          511.5         785.\n",
      "  773.          764.          440.66666667  827.25        683.2\n",
      "  880.         1093.          571.         1093.         1093.\n",
      "  837.5         482.         1093.         1093.          523.75\n",
      "  437.5         674.          657.         1093.         1093.\n",
      "  813.5        1093.         1093.          628.         1093.\n",
      " 1093.          419.5        1093.          580.625       751.5\n",
      " 1093.          811.         1093.         1082.5         737.\n",
      "  563.28571429  568.66666667 1093.          494.          546.\n",
      "  559.5         551.66666667  797.          546.          901.\n",
      "  711.         1093.          557.66666667  540.          612.\n",
      "  762.          580.625       968.         1093.         1093.\n",
      "  799.         1093.          694.66666667  751.5        1093.\n",
      "  494.          593.66666667  907.5        1093.         1093.\n",
      " 1093.          738.          608.66666667 1093.         1093.\n",
      "  624.25        654.         1093.         1093.          644.66666667\n",
      "  602.6         642.          551.66666667  577.          865.\n",
      "  614.33333333  546.          533.28571429 1093.         1093.\n",
      "  533.28571429 1045.          513.55555556  540.         1093.\n",
      "  632.          509.55555556 1093.         1093.          646.\n",
      "  667.5         566.5         430.2         548.          584.\n",
      "  968.          820.8         762.          468.6         781.\n",
      "  529.8         879.          504.7        1093.          509.55555556\n",
      " 1093.         1093.         1093.          870.          498.\n",
      "  674.         1093.         1093.          453.33333333  740.\n",
      " 1093.         1093.         1093.          507.66666667  704.\n",
      "  667.5         583.         1093.          484.42857143 1093.\n",
      " 1093.         1093.          477.375       591.         1093.\n",
      "  537.          707.          671.         1093.          495.6\n",
      "  738.         1093.          827.25        654.         1093.\n",
      " 1093.          597.42857143  938.          773.         1093.\n",
      "  464.5         525.6         513.55555556  611.          477.375\n",
      " 1085.          543.          851.5         547.          780.\n",
      " 1093.         1093.          865.          541.4         606.\n",
      "  647.         1093.         1093.          568.66666667  822.33333333\n",
      "  697.          910.         1093.          501.5        1093.\n",
      " 1093.         1093.          827.25       1093.          636.\n",
      "  525.6         444.          831.5         555.5        1093.\n",
      "  647.          590.          862.          666.          692.\n",
      "  611.          506.         1093.          738.          570.\n",
      "  518.5         459.5         742.5        1093.          444.\n",
      " 1093.          774.         1093.         1093.          549.22222222\n",
      " 1093.          533.28571429 1093.          670.         1093.\n",
      "  726.5         787.          584.          482.         1093.\n",
      "  787.         1093.         1093.          800.4        1093.\n",
      " 1093.          660.          874.5         529.8         606.\n",
      " 1093.         1093.         1093.          456.         1093.\n",
      "  597.42857143  718.75        537.          774.          541.4\n",
      " 1093.          774.          667.5        1093.          501.5\n",
      " 1093.          540.          509.55555556 1093.          654.\n",
      " 1002.5        1093.         1093.         1093.         1093.\n",
      "  501.5         593.66666667  761.          511.5        1093.\n",
      "  516.42857143 1093.          484.42857143  831.5         543.\n",
      " 1093.         1093.          492.57142857  511.5         622.5\n",
      "  717.          866.         1093.          633.25       1093.\n",
      " 1065.          503.         1093.          482.          614.33333333\n",
      "  765.         1093.         1093.          504.7        1093.\n",
      " 1093.          490.3125      503.          588.8         533.28571429\n",
      "  521.          713.75        968.          516.42857143  658.5\n",
      "  672.75       1093.         1093.         1093.         1093.\n",
      "  652.33333333  537.          664.          593.66666667 1093.\n",
      " 1093.          575.33333333 1093.          851.5         670.\n",
      "  563.28571429 1093.          593.66666667  482.          834.\n",
      "  419.5         507.66666667 1093.         1093.          652.33333333\n",
      "  622.5         494.          557.66666667 1093.          597.42857143\n",
      "  774.          817.5         968.          748.         1093.\n",
      "  721.          525.6         575.33333333  599.         1093.\n",
      "  482.         1093.          644.66666667  523.75       1093.\n",
      "  498.          866.          759.2         580.625       518.5\n",
      " 1093.         1093.          549.22222222  729.5        1093.\n",
      " 1093.          572.33333333  797.          583.          644.66666667\n",
      "  667.5         810.          537.          654.          644.66666667\n",
      "  525.6         507.66666667  642.          578.          756.5\n",
      " 1093.          531.         1093.         1093.         1093.\n",
      "  660.          843.          430.2         652.33333333  504.7\n",
      "  543.         1093.         1093.          704.         1093.\n",
      "  398.          851.5         559.5         618.33333333  664.\n",
      " 1093.          523.75       1093.          575.33333333 1093.\n",
      "  751.5         800.4         664.         1093.         1082.5\n",
      "  504.7         547.          525.6         450.4        1093.\n",
      "  618.33333333  810.          789.66666667 1093.          813.5\n",
      "  843.          620.25        453.33333333 1093.          608.66666667\n",
      "  805.          557.66666667 1093.          792.5         580.625\n",
      "  764.          632.          787.          671.         1093.\n",
      " 1093.         1093.         1093.         1093.          527.7\n",
      "  854.          774.         1093.          843.          767.6\n",
      "  488.33333333 1093.          511.5         490.3125      509.55555556\n",
      " 1093.         1093.          457.5         694.66666667  516.42857143\n",
      " 1093.         1093.         1093.         1093.          711.\n",
      "  784.          851.5         516.42857143  859.         1093.\n",
      " 1093.         1093.         1093.         1093.          539.\n",
      "  482.          482.          851.5         504.7         658.5\n",
      " 1093.         1045.          612.          549.22222222  729.5\n",
      " 1093.          507.66666667 1093.          544.25        536.\n",
      "  732.33333333  746.5         635.         1093.         1093.\n",
      "  759.2        1093.          482.          559.5         611.\n",
      "  572.33333333 1093.          501.5        1093.          646.\n",
      " 1093.          548.         1093.          738.         1093.\n",
      "  498.          457.5         638.5         409.          870.\n",
      "  448.5         497.          495.6        1093.          674.\n",
      "  749.5         756.5         549.22222222  482.          720.\n",
      "  525.6        1093.          686.          572.33333333 1093.\n",
      "  580.625       887.         1093.         1093.          509.55555556\n",
      "  670.         1093.          880.         1093.          831.5\n",
      " 1093.          495.6         497.          468.6        1093.\n",
      "  880.         1093.          713.75        591.         1093.\n",
      "  840.          874.5         495.6        1093.          860.5\n",
      "  856.          608.66666667  751.5         846.          826.\n",
      "  600.5        1093.          860.5         521.          758.\n",
      " 1093.          723.          709.          808.          827.25\n",
      "  413.          709.          652.33333333  815.         1093.\n",
      "  740.          840.          608.66666667  667.5         544.25\n",
      "  466.5        1093.         1093.          683.2        1093.\n",
      " 1093.          591.          716.         1093.          537.\n",
      "  608.66666667  751.5         466.5         448.5         764.\n",
      "  434.         1093.         1093.         1093.          762.\n",
      "  880.          629.          501.5        1093.         1093.\n",
      " 1093.          860.5         636.          535.          837.5\n",
      " 1093.         1093.          525.6         518.5        1093.        ]\n",
      "r2_score: 1.0\n",
      "mean_absolute_error: 0.653\n"
     ]
    }
   ],
   "source": [
    "print(gs_result.best_params_)\n",
    "print(gs_result.best_score_)\n",
    "print(gs_result.predict(regression_test))\n",
    "pred: object = gs_result.predict(regression_test)\n",
    "print(f\"r2_score: {round(r2_score(test, pred), 3)}\")\n",
    "print(f\"mean_absolute_error: {round(mean_absolute_error(test, pred), 3)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 14. Постройте итоговое дерево регрессии"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "graph = export_graphviz(\n",
    "    clf,\n",
    "    out_file =  \"data/regression.dot\",\n",
    "    filled = True,\n",
    "    rounded = True\n",
    ")\n",
    "print(graph)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ответы на контрольные вопросы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Опишите этапы построения алгоритма дерева решений для задачи классификации и регрессии. Чем они отличаются и чем схожи?\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Какие метрики используются для оценки качества работы алгоритмов при решении задачи регрессии? Опишите данные метрики с математической точки зрения и скажите, чем они отличаются друг от друга.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Каким способом можно повысить качество работы алгоритмов регрессии?"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}